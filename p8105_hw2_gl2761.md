p8105_hw2_gl2761
================
Gonghao Liu
10/4/2022

### Problem 1

``` r
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

These code chunk first import the dataset, then convert the 4 route
variables from num to char, `janitor::clean` was use to get a clean
column name. Then use `select` function to select the column we want.
Finally, update values in entry column from ‘yes’ and ‘no’ to ‘TRUE’ and
‘FALSE’.

The following code chunk selects station name and line, and then uses
`distinct()` to obtain all unique combinations. As a result, the number
of rows in this dataset is the number of unique stations.

``` r
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 465 × 2
##    station_name             line    
##    <chr>                    <chr>   
##  1 25th St                  4 Avenue
##  2 36th St                  4 Avenue
##  3 45th St                  4 Avenue
##  4 53rd St                  4 Avenue
##  5 59th St                  4 Avenue
##  6 77th St                  4 Avenue
##  7 86th St                  4 Avenue
##  8 95th St                  4 Avenue
##  9 9th St                   4 Avenue
## 10 Atlantic Av-Barclays Ctr 4 Avenue
## # … with 455 more rows
```

There are 465 distinct stations here.

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 84 × 2
##    station_name                   line           
##    <chr>                          <chr>          
##  1 Atlantic Av-Barclays Ctr       4 Avenue       
##  2 DeKalb Av                      4 Avenue       
##  3 Pacific St                     4 Avenue       
##  4 Grand Central                  42nd St Shuttle
##  5 34th St                        6 Avenue       
##  6 47-50th Sts Rockefeller Center 6 Avenue       
##  7 Church Av                      6 Avenue       
##  8 21st St                        63rd Street    
##  9 Lexington Av                   63rd Street    
## 10 Roosevelt Island               63rd Street    
## # … with 74 more rows
```

There are 84 stations are ADA compliant.

To compute the proportion of station entrances / exits without vending
allow entrance, we first exclude station entrances that do not allow
vending. Then, we focus on the `entry` variable – this logical, so
taking the mean will produce the desired proportion (recall that R will
coerce logical to numeric in cases like this).

``` r
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
## [1] 0.3770492
```

There are 37.70492% of station entrance / exists without vending allow
entrance.

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. As a first
step, we tidy the data as alluded to previously; that is, we convert
`route` from wide to long format. After this step, we can use tools from
previous parts of the question (filtering to focus on the A train, and
on ADA compliance; selecting and using `distinct` to obtain dataframes
with the required stations in rows).

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 60 × 2
##    station_name                  line           
##    <chr>                         <chr>          
##  1 Times Square                  42nd St Shuttle
##  2 125th St                      8 Avenue       
##  3 145th St                      8 Avenue       
##  4 14th St                       8 Avenue       
##  5 168th St - Washington Heights 8 Avenue       
##  6 175th St                      8 Avenue       
##  7 181st St                      8 Avenue       
##  8 190th St                      8 Avenue       
##  9 34th St                       8 Avenue       
## 10 42nd St                       8 Avenue       
## # … with 50 more rows

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 17 × 2
##    station_name                  line            
##    <chr>                         <chr>           
##  1 14th St                       8 Avenue        
##  2 168th St - Washington Heights 8 Avenue        
##  3 175th St                      8 Avenue        
##  4 34th St                       8 Avenue        
##  5 42nd St                       8 Avenue        
##  6 59th St                       8 Avenue        
##  7 Inwood - 207th St             8 Avenue        
##  8 West 4th St                   8 Avenue        
##  9 World Trade Center            8 Avenue        
## 10 Times Square-42nd St          Broadway        
## 11 59th St-Columbus Circle       Broadway-7th Ave
## 12 Times Square                  Broadway-7th Ave
## 13 8th Av                        Canarsie        
## 14 Franklin Av                   Franklin        
## 15 Euclid Av                     Fulton          
## 16 Franklin Av                   Fulton          
## 17 Howard Beach                  Rockaway
```

There are 60 distinct stations serve the A train and 17 stations are ADA
compliant.

### Problem 2

Read and clean the Mr. Trash Wheel sheet.

``` r
trash_wheel = read_excel("data/Trash Wheel Collection Data.xlsx", 
                         sheet = "Mr. Trash Wheel", 
                         range = "A2:N547")%>%
  janitor::clean_names()%>%
  drop_na(dumpster)%>%
  mutate(sports_balls = as.integer(round(sports_balls))) %>%
  # New column to track sheet
  mutate(sheet = "Mr. Trash Wheel")
```

Read and clean the Porfessor Trash Wheel sheet.

``` r
pro_trash_wheel = read_excel("data/Trash Wheel Collection Data.xlsx", 
                         sheet = "Professor Trash Wheel", 
                         range = "A2:M96")%>%
  janitor::clean_names()%>%
  drop_na(dumpster)%>%
  # New column to track sheet
  mutate(sheet = "Professor Trash Wheel") %>%
  # Create a new column and convert the variable to combine the datasets
  mutate(sports_balls = 0) %>%
  mutate(year = as.character(year))
```

Combine the pro_trash_wheel and trash_wheel as one dataset.

``` r
combined_trash_wheel = 
  bind_rows(trash_wheel, pro_trash_wheel)
```

Write a paragraph about data:

In Trash Wheel data, it has key variables: dumpster, month, year, date,
weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
cigarette_butts, glass_bottles, grocery_bags, chip_bags, sports_balls,
homes_powered, sheet, with number of 15 and has 545 observations.

In Porfessor Trash Wheel data, it has key variables: dumpster, month,
year, date, weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags,
homes_powered, sheet, sports_balls, with number of 15 and has 94
observations.

In Combined Trash Wheel data, it has key variables: dumpster, month,
year, date, weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags,
sports_balls, homes_powered, sheet, with number of 15 and has 639
observations.

The total weight of trash collected by Professor Trash Wheel is 190.12.

The the total number of sports balls collected by Mr. Trash Wheel in
2020 is 856.

### Problem 3

Read and clean data in pols_month.

``` r
pols_month = read_csv("./fivethirtyeight_datasets/pols-month.csv")%>%
  janitor::clean_names()%>%
  separate(mon, into = c("year", "month", "day"))%>%
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    month = month.name[month],
    president = ifelse(prez_dem == "1", "dem", "gop")
    )%>%
  select(- day, -prez_dem, -prez_gop)%>%
relocate(year, month, president)
```

Read and clean the data snp.csv as well, arrange according to year and
month, and organize columns.

``` r
snp = read_csv("./fivethirtyeight_datasets/snp.csv")%>%
  janitor::clean_names()%>%
  mutate(date = lubridate::mdy(date))%>%
  separate(date, into = c("year", "month", "day"))%>%
  mutate(
   month = as.integer(month),
   month = month.name[month],
   year = as.integer(year),
   year = ifelse(year>2021, year - 100, year)
  )%>%
  select(-day)%>%
  arrange(year, month)%>%
  relocate(year,month)
```

Read and clean the unemployment data.

``` r
unemployment_data = read_csv("./fivethirtyeight_datasets/unemployment.csv")%>%
  janitor::clean_names()
colnames(unemployment_data) = c("year","January","February","March","April","May","June","July","August","September","October","November","December")

unemployment_tidy = 
  unemployment_data %>%
  pivot_longer(
    January:December,
    names_to = "month",
    values_to = "unemp_percent"
  )%>%
  drop_na()%>%
  relocate(year, month)
```

Join the datasets.

``` r
pols_snp = left_join(pols_month, snp, by = c("year", "month"))

pols_snp_unemp = left_join(pols_snp, unemployment_tidy, by = c("year", "month"))
```

A short paragraph about these data sets. In our pols_month data set, it
shows the number of national politicians who are democratic or
republican at any given time. It has 9 variables which are year, month,
president, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, and has
822 observations. The time period is from 1947 to 2015.

In snp data set, it shows Standard & Poor’s stock market index (S&P). It
has 3 variables including year, month, close, and has 787 observations.
The time period is from 1950 to 2015.

In unemployment data set, it has 3 variables with the name of year,
month, unemp_percent, and it has 810 observations. Time range is between
1948 to 2015.

In the first combined data set, it combined pols_month data and snp
data, with dimension 822 and 10. Variables include year, month,
president, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, close.
Time period is from 1947 to 2015.

The last dataset contains pols_month data, snp data and unemployment
data, with 822 observations and 11 variables. Variables include year,
month, president, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem,
close, unemp_percent. Time period is from 1947 to 2015.
